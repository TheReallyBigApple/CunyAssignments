---
title: "Final Notes"
output:
  html_document:
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE,results = "hold")
```


<style type="text/css">
                      .tab { margin-left: 60px; }
                      .font { color: blue; }
</style>

```{r}

library(jpeg)         # for readJPEG
library(OpenImageR)   # for flipImage

```




<br><br><br><br>

<font size="7" color="purple">Principal Component Analysis and Confusion Matrix</font>

<br><br><br>



***

# Prepare Data

***



<br>


Bring in the Training and Test Data Sets.

<br>


<font size="4" color="purple">TO DO: put data on github</font>

<br>

```{r}

#  The first column of the Training set is the label, "zero" through "nine"


base_path="C:\\Users\\arono\\source\\R\\Data605\\Final\\Problem 2 PCA Images\\"
pathnpic<-paste0(base_path,"train.csv" )
train_df=read.csv(pathnpic, stringsAsFactors=F)  #read in the raw data

train_labels=train_df[,1] 
train_df[,1]=NULL  


pathnpic<-paste0(base_path,"test.csv" )
test_df=read.csv(pathnpic, stringsAsFactors=F)


train_vec=as.vector(unlist(train_df)) 
train_arr=array(train_vec, dim=c(nrow(train_df),28,28))

test_vec=as.vector(unlist(test_df)) 
test_arr=array(train_vec, dim=c(nrow(test_df),28,28))

rm(train_vec)
rm(test_vec)
rm(train_df)
rm(test_df)

```

<br>

<i>3. Using the training.csv file, plot representations of the first 10 images to understand the data format.</i>

<br>

```{r}

# dim(train_arr)    # 42000 28 28

par(mfrow=c(2,5))

for (i in 1:10){ 
  image(1:28, 1:28, flipImage(train_arr[i,,]))
}


```

<br>

<i>3. Go ahead and divide all pixels by 255 to produce values between 0 and 1.</i>

<br>

```{r}

train_arr<-train_arr/255


```



***

# Analyze Data

***


<br>

<i>4. What is the frequency distribution of the numbers in the dataset?</i>

<br>

```{r}
hist(train_vec, breaks = 100)
```


<br>

We can create a frequency table with the table() function. Lets look at the most frequent intensities.

<br>


```{r}

train_freq<-table(train_vec)

tail(sort(train_freq))
     
```

<br>

If we remove the pure white, We can get a better histogram on the other values

<br>

```{r}


logInd<-train_arr>0

hist(train_arr[logInd], breaks = 100, freq = FALSE)


```

<br>

<i>5. For each number, provide the mean pixel intensity. What does this tell you? </i>

<br>

```{r}

mean(train_arr)

```

<br>

A lower value indicates darker images. Pure black is the absence of color and white is full color.

These images are fairly dark.

The eigen shoe images we worked with were filled with pure white (RGB values of 255) and the mean intensity was around .8

<br>

***

# PCA

***


<br>

<i>6. Reduce the data by using principal components that account for 95% of the variance. How many
components did you generate? Use PCA to generate all possible components (100% of the
variance). How many components are possible? Why? </i>

<br>

PCA will produce 784 components. Each pixel intensity represents a response for each image.

<br>

We can either use prcomp() or scale(), cor() and eigen(). Below uses scale(), cor() and eigen()
<br>


```{r}

# convert this to 784 rows (pixels) and 42000 columns (images)
train_flat_mat<-t(matrix(train_arr, ncol=28*28, byrow = FALSE))

raw_scaled<-scale(train_flat_mat, scale = FALSE)
raw_cor<-raw_scaled %*% t(raw_scaled) / (nrow(raw_scaled)-1)
raw_eigen <- eigen(raw_cor)

cum.var  <- cumsum(raw_eigen$values) / sum(raw_eigen$values)
thres    <- min(which(cum.var > .95))

sprintf("Saving off the top %d principal components",thres)
top_loadings<-raw_eigen$rotation[1:thres,]

```


<br>

Here we use prcomp() and display a scree plot to get a visual of how many Eigen Values are close to zero.

<br>

```{r}

train_pca<-prcomp(train_flat_mat, scale = TRUE)

var_explained = train_pca$sdev^2 / sum(train_pca$sdev^2)

#create scree plot
library(ggplot2)

qplot(c(1:784), var_explained) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Scree Plot") 

```

<br>


<i>7. Plot the first 10 images generated by PCA. They will appear to be noise. Why?</i>

<br>

```{r}


par(mfrow=c(2,5))

for (i in 1:10) {
  image(1:28,1:28,array(train_pca$x[,i], dim=c(28,28)))
}


```


This represents variances among all 9 digits so it looks smudgy. 

<br>

You can sort of see that the patches get darker in spots that most numbers go through.

<br>



<i>8. Now, select only those images that have labels that are 8â€™s. Re-run PCA that accounts for all of
the variance (100%). Plot the first 10 images. What do you see?  </i>

```{r}

eights<-which(train_labels == 8)
dim(train_arr)
train_eights<-train_arr[eights,,]
train_flat_mat<-t(matrix(train_eights, ncol=28*28, byrow = FALSE))
pca<-prcomp(train_flat_mat, scale = TRUE)

par(mfrow=c(2,5))

for (i in 1:10) {
  image(1:28,1:28,array(pca$x[,i], dim=c(28,28)))
}

```

<br>

Looks like 8s. Each successive image gets more and more blurry or more specifically it contrasts more and in different spots.

<br>

***

# Predictions and Confustion Matrix

***




<br>


<i>9. An incorrect approach to predicting the images would be to build a linear regression model with
y as the digit values and X as the pixel matrix. Instead, we can build a multinomial model that
classifies the digits. Build a multinomial model on the entirety of the training set. Then provide
its classification accuracy (percent correctly identified) as well as a matrix of observed versus
forecast values (confusion matrix). This matrix will be a 10 x 10, and correct classifications will
be on the diagonal. </i>

<br>

```{r}

# convert this to 784 rows (pixels) and 42000 columns (images)
train_flat_mat<-t(matrix(train_arr, ncol=28*28, byrow = FALSE))


# add labels to train_flat_mat and reduce the size to 7K to prevent memory issues
train_flat_new<-as.data.frame(cbind(train_labels, t(train_flat_mat)  ))
train_flat_new<-train_flat_new[1:7000,]




digit_model <- nnet::multinom(train_labels ~., data = train_flat_new, MaxNWts =10000000)


# put your test matrix togehter
test_flat_new<-train_flat_new[7:14000,]
test_flat_new_na<-test_flat_new[,-1]

dim(test_flat_new)

# Summarize the model -- not responding
summary(digit_model)




```


<br>

Display the summary of predict() and the success rate based on the known labels.

<br>




```{r}

# Make predictions
predicted.classes <- digit_model %>% predict(test_flat_new)

summary(predicted.classes)

true_or_false<-(predicted.classes == test_flat_new$train_labels)

results<-table(predicted.classes == test_flat_new$train_labels)

success_rate<-results[2]/(results[1]+results[2])

sprintf("The success rate is %.f", success_rate)

```


<br>

Print out the confusion matrix. Not sure why its called confused but the grid shows the predicted vs actual classification of each image.

<br>


```{r}


confusionMatrix(
  factor(predicted.classes),
  factor(test_flat_new$train_labels))  

```

